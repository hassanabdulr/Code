---
title: "SPIN-R"
output: html_document
date: "`r Sys.Date()`"
---

load libraries 

```{r}
library(tidyr)
library(dplyr)
library(ggplot2)
library(lubridate)

```

Load up data

```{r}

Data <- read.csv("/home/aabdulrasul/Documents/Projects/SPINR/SPN30IdentificationO_DATA_2024-09-05_1113.csv")

# Run any pre-processing steps here that make the data readable - e.g, turn blanks "" into NA

# Replace blank with NA

replace_blank_with_na <- function(x) {
  if (is.character(x)) {
    x <- na_if(x, "")
  }
  return(x)
}

Data <- Data %>% mutate(across(everything(), ~ replace_blank_with_na(.)))
  
```


### Merge


Data set has 4 arms, we will separate them into 4 separate data frames. The logic behind this is to clean and process each on before we merge them into one final data frame

```{r}

Arm1 <- Data %>% filter(grepl("_arm_1$", redcap_event_name)) # ASD
Arm2 <- Data %>% filter(grepl("_arm_2$", redcap_event_name)) # SSD in SPINS
Arm3 <- Data %>% filter(grepl("_arm_3$", redcap_event_name)) # Control
Arm4 <- Data %>% filter(grepl("_arm_4$", redcap_event_name)) # Repeat scan using some of the original study 
```

Filter out time_points in Arm4

```{r}

# Specifically in Arm4 we have instances where record_ids have separate rows for their respective time points. We want to ensure the merging process does not treat these instances as one. As such we are going to filter out these instances and save them in a new data frame _tx2 

Arm4_tx2 <- Arm4 %>% 
  filter(redcap_event_name == "tx2_arm_4")

Arm4 <- Arm4 %>%
  filter(redcap_event_name != "tx2_arm_4")

# For some reason Arm4 has a record_id named test - we will filter this out too

Arm4 <- Arm4 %>%
  filter(record_id != "test")
```



### Merge : Find Duplicates

Compare record_ids between the arms to determine if there are any duplicates.

```{r}

# First, extract the record_id columns from each dataframe
record_ids_arm_1 <- Arm1$record_id
record_ids_arm_2 <- Arm2$record_id
record_ids_arm_3 <- Arm3$record_id
record_ids_arm_4 <- Arm4$record_id

# Find common record_ids between each pair of arms
common_arm_1_2 <- intersect(record_ids_arm_1, record_ids_arm_2)
common_arm_1_3 <- intersect(record_ids_arm_1, record_ids_arm_3)
common_arm_1_4 <- intersect(record_ids_arm_1, record_ids_arm_4)
common_arm_2_3 <- intersect(record_ids_arm_2, record_ids_arm_3)
common_arm_2_4 <- intersect(record_ids_arm_2, record_ids_arm_4)
common_arm_3_4 <- intersect(record_ids_arm_3, record_ids_arm_4)

# Print the results
cat("Common IDs between Arm 1 and Arm 2:", common_arm_1_2, "\n")
cat("Common IDs between Arm 1 and Arm 3:", common_arm_1_3, "\n")
cat("Common IDs between Arm 1 and Arm 4:", common_arm_1_4, "\n")
cat("Common IDs between Arm 2 and Arm 3:", common_arm_2_3, "\n")
cat("Common IDs between Arm 2 and Arm 4:", common_arm_2_4, "\n")
cat("Common IDs between Arm 3 and Arm 4:", common_arm_3_4, "\n")
```


Filter out problematic duplicate record id : SPN30_CMH_043281 exists in both Arm2 and Arm4, however, Arm2 has a partially completed timepoint 1 dataset, this is causing some issues in the merge process as the same participant seemingly has completed the timepoint 1 battery in Arm4 which was completed a couple of days apart from Arm2. As such we can assume Arm4 is the more accurate dataset. therefore we will remove SPN30_CMH_043281 from Arm2.



```{r}
Arm2 <- Arm2 %>%
  filter(record_id != "SPN30_CMH_043281")
```


### Merge : Standardize duplicates

Now that we've determined Arm 2 and Arm 4 both have duplicates, we need to ensure that the information in these data frames are in fact duplicates of each other - or whether one has more data points filled than the other. We will essentially compare the 2 and then copy whatever is extra onto Arm 4 (as we are currently working with this data set).

Note that this is hard coded for Arm4 and Arm2, update and adapt where applicable based on the results of the previous cell


```{r}

# Identify common record_ids across Arm2 and 4
common_arm_2_4 <- intersect(Arm2$record_id, Arm4$record_id) 

# Filter both data frames to include only the common record IDs
filtered_Arm2 <- Arm2 %>% filter(record_id %in% common_arm_2_4)
filtered_Arm4 <- Arm4 %>% filter(record_id %in% common_arm_2_4)

# Merge the filtered data from Arm2 and 4 based on record_id
comparison_df <- merge(filtered_Arm2, filtered_Arm4, by = "record_id", suffixes = c("_arm2", "_arm4"))

# Compare each column and update directly
for (col in setdiff(names(filtered_Arm2), "record_id")) {
  col_arm2 <- paste0(col, "_arm2")
  col_arm4 <- paste0(col, "_arm4")
  
  # Compare and decide to update
  comparison_df[[col_arm4]] <- ifelse(comparison_df[[col_arm2]] != comparison_df[[col_arm4]] & !is.na(comparison_df[[col_arm2]]),
                                      comparison_df[[col_arm2]],
                                      comparison_df[[col_arm4]])
}

# Drop the arm2 columns and rename arm4 columns to their original names
updated_arm_4 <- comparison_df %>%
  select(record_id, ends_with("_arm4")) %>%
  rename_with(~ sub("_arm4", "", .), ends_with("_arm4"))


# Append these rows to updated_arm_4
complete_arm_4 <- bind_rows(updated_arm_4,  anti_join(Arm4, updated_arm_4, by = "record_id"))

```


Now that we have the completed arms, we will now designate them into their respective groups

Arm1 corresponds to ASD
Arm2 corresponds to SSD/SPINS
Arm3 corresponds to Control
Arm4 corresponds to SPINR (not this will include the duplicates seen in Arm2)

```{r}
Arm1 <- Arm1 %>%
  mutate(redcap_event_name = "ASD") %>%
  rename(group = redcap_event_name)

Arm2 <- Arm2 %>%
  mutate(redcap_event_name = "SSD") %>%
  rename(group = redcap_event_name)

Arm3 <- Arm3 %>%
  mutate(redcap_event_name = "Control") %>%
  rename(group = redcap_event_name)

complete_arm_4 <- complete_arm_4 %>%
  mutate(redcap_event_name = "SPINR") %>%
  rename(group = redcap_event_name)
```


(Optional) Remove intermediary data frames

```{r}
rm(comparison_df, filtered_Arm2, filtered_Arm4, updated_arm_4)
```


Now that we have the duplicates sorted we can now merge the arms together, note that we are going to merge Arm1, Arm2, Arm3 and Arm4. The steps above have effectively combined the duplicates seen in Arm2 and Arm4 under complete_arm_4 which means that when we merge the arms together, we need to ensure we are ONLY merging the non-duplicates from Arm2. All Arms will be merged as the dataframe MergedDF 

```{r}

# Merge all arms together into one dataframe. Anti_join is used here to find the unique record_ids between Arm2 and complete_arm_4 thereby allowing us to merge the non duplicates in Arm2, 

MergedDF <- bind_rows(Arm1, anti_join(Arm2, complete_arm_4, by = "record_id"), Arm3, complete_arm_4)

# We will now collapse repeated record_ids to form one record_id filling in 

# Collapse duplicate record_id entries in MergedD` by grouping by record_id and summarizing each column for each column within the same `record_id`. Using ~na.omit we remove all NA values and retain only the first non-NA value encountered, therefore it doesn't matter whether the non-NA value is in the first or second row. This gives us a single consolidated row per record_id if a duplicate exists (there are no triple repeats). If all values are NA within a column for a specific record_id, the resulting value for that column will be NA.

MergedDF <- MergedDF %>%
  group_by(record_id) %>%
  summarise_all(~na.omit(.)[1])

```


Create groups corresponding to arm participant is from


Some metrics for us to keep track of (in case we were wondering)

Note we have recruited 88 participants total (see recruitment.rmd)

```{r}

cat("Data collected from", sum(MergedDF$elg_form_complete == "1", na.rm = TRUE), "Eligible Participants\n")

```


## Demographics

```{r}

# Create a new dataframe SPINR_demo which will house the main demographic information from MergedDF. This includes the participants, age at the start of the study, their handedness, group, assigned sex at birth, race, highest education amd neuropsych composite score

# This was adapted from SPASD_SPINS_redcap_wrangling.Rmd

SPINR_demo <-
  MergedDF %>%
  select(record_id, group, demo_doa, np_fact_handedness,
         demo_sex_birth, demo_age_study_entry,
         demo_race___1_asian_east, demo_race___2_asian_southeast, demo_race___3_asian_south,
         demo_race___4_black_african, demo_race___5_black_na, demo_race___6_black_carribean,
         demo_race___7_firstnations, demo_race___8_indian_caribbean, demo_race___9_indigenous, demo_race___10_inuit,            demo_race___11_latin, demo_race___12_metis, demo_race___13_middleeastern, demo_race___14_white,                        demo_race___15_white_na, demo_race___16_mixed, demo_race___17_noanswer, demo_race___18_unknown,                        demo_race___19_other, demo_highest_grade_self, np_composite_tscore) %>%

  # We are setting assigned sex at birth as a factor for analysis
  
    mutate(sex = factor(demo_sex_birth,
                      levels = c(1, 2, 3, 4),
                      labels = c("Female", "Male", "Intersex", "Prefer not to Answer")),
 
  # Renaming the responses for the demo race drop down to be more clear. case_when used to vectorise the data thereby giving us one column - race - with the respective participants responses.
  
            race = case_when(
                          demo_race___1_asian_east == 1 ~ "Asian - East",
                          demo_race___2_asian_southeast == 1 ~ "Asian - South East",
                          demo_race___3_asian_south == 1 ~ "Asian - South Asia",
                          demo_race___4_black_african == 1 ~ "Black - African",
                          demo_race___5_black_na == 1 ~ "Black - African American",
                          demo_race___6_black_carribean == 1 ~ "Black - Caribbean",
                          demo_race___7_firstnations == 1 ~ "Native - First Nation",
                          demo_race___8_indian_caribbean == 1 ~ "South Asian - Caribbean",
                          demo_race___9_indigenous == 1 ~ "Native - American",
                          demo_race___10_inuit == 1 ~ "Native - Inuit",
                          demo_race___11_latin == 1 ~ "Latin American",
                          demo_race___12_metis == 1 ~ "Native - Metis",
                          demo_race___13_middleeastern == 1 ~ "Middle Eastern",
                          demo_race___14_white == 1 ~ "White - European",
                          demo_race___15_white_na == 1 ~ "White - North American",
                          demo_race___16_mixed == 1 ~ "More than one race",
                          demo_race___17_noanswer == 1 ~ "No Answer",
                          demo_race___18_unknown == 1 ~ "Unknown",
                          demo_race___18_unknown == 1 ~ "Other" ))

# Construct final dataframe with the post processed columns

SPINR_demo <- SPINR_demo %>%
  select(record_id, group, demo_doa, np_fact_handedness, sex, demo_age_study_entry, race, demo_highest_grade_self, np_composite_tscore)
                          
        
```


## Neuropsych Assessments

The following Neuropsych assessments are collected, RMET (Reading The Mind in The Eyes Test), ER-40 (Penn Emotion Recognition Test), and, TASIT-R (The Awareness of Social Inference Test - Revised) Along with various clinical assessments. We will create a new dataframe combining all of these into one from MergedDF - this new dataframe will be called SPINR_neuro

Adapted from SPASD_SPINS_redcap_wrangling.Rmd

```{r}


SPINR_neuro <-
    MergedDF %>%
      select(record_id, group, np_fact_handedness,
             
             # Brief Psychiatric Rating Scale
             
             bprs_factor_anxiety_depression,
             bprs_factor_neg_symp,
             bprs_factor_pos_symp,
             bprs_factor_activation,
             bprs_factor_hostility,
             
             # Neuropsych Summary Scores
             
             np_domain_tscore_process_speed,
             np_domain_tscore_att_vigilance,
             np_domain_tscore_work_mem,
             np_domain_tscore_verbal_learning,
             np_domain_tscore_visual_learning,
             np_domain_tscore_reasoning_ps,
             np_domain_tscore_social_cog,
             
             # Interpersonal Reactivity Index
             
             iri_factor_pt,
             iri_factor_fs,
             iri_factor_ec,
             iri_factor_pd,
             iri_total,
             
             # Birchwood Social Functioning Scale
             
             bsfs_sec1_total,
             bsfs_sec2_total,
             bsfs_sec3_total,
             bsfs_sec4_total,
             bsfs_sec5_total,
             bsfs_sec6_total,
             bsfs_sec7_y_total_7a,
             bsfs_sec7_n_total_7b,   
             bsfs_sec7_y_total_7a,
             bsfs_sec_grandtotal1,
             bsfs_sec_grandtotal2,
          
             # Penn Emotion Recognition Test
             
             er40_cr,
             er40_crt,
             er40ang,
             er40fear,
             er40hap,
             er40noe,
             er40sad,
             er40_fpa,
             er40_fpf,
             
             # Reading The Mind In The Eyes Test
           
             rmet_total,
             
             # The Awareness Of Social Inference Test-Revised (TASIT)
             
             tasit_part1_happyscore, 
             tasit_part2_surprisedscore,
             tasit_part3_neutralscore,
             tasit_part4_sadscore,
             tasit_part5_angryscore,
             tasit_part6_anxiousscore,
             tasit_part7_revoltedscore,
             
             tasit_positive_total,
             tasit_negative_total,
             tasit_correct_total,
             tasit_part2_grandtotal,
             tasit_part2_total_do_sincere,
             tasit_part2_total_say_sincere,
             tasit_part2_total_think_sincere,
             tasit_part2_total_feel_sincere,
             tasit_part2_total_do_s_sarcasm,
             tasit_part2_total_say_s_sarcasm,
             tasit_part2_total_think_s_sarcasm,
             tasit_part2_total_feel_s_sarcasm,
             tasit_part2_total_do_p_sarcasm,
             tasit_part2_total_say_p_sarcasm,
             tasit_part2_total_think_p_sarcasm,
             tasit_part2_total_feel_p_sarcasm,
             
             tasit_part2_total_sincere,
             tasit_part2_total_s_sarcasm,
             tasit_part2_total_p_sarcasm,
             
             # TAST - Total Number of items correct
             
             tasit_part2_total_do,
             tasit_part2_total_say,
             tasit_part2_total_think,
             tasit_part2_total_feel,
             
  
             # TASIT - Total Correct Sarcastic - Do, Say, Think, Feel
             
             tasit_part3_total_sarcastic_do,
             tasit_part3_total_sarcastic_say,
             tasit_part3_total_sarcastic_think,
             tasit_part3_total_sarcastic_feel,
             
             # TASIT - Total Correct - Text and Visual Cues
             
             tasit_part3_grandtotal_text,
             tasit_part3_grandtotal_visual,
             
             # TASIT - Total Correct - Do, Say, Think, Feel
             
             tasit_part3_grandtotal_do,
             tasit_part3_grandtotal_say,
             tasit_part3_grandtotal_think,
             tasit_part3_grandtotal_feel,
             
             # Schizotypal Personality Questionnaire-Brief
             
             spqb_total,
             
             # Adult Autism-Spectrum Quotient
             
             aq_total,
             
             # Beck Depression Inventory
             
             total_score)
             
             
             
             

             
             
      
    
    

```



